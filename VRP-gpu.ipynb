{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import cuda, jit, int32, float32, int64\n",
    "from numba.cuda.random import create_xoroshiro128p_states, xoroshiro128p_uniform_float32\n",
    "from math import pow, hypot, ceil\n",
    "import random\n",
    "from pdb import set_trace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read The problem data file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class vrp():\n",
    "    def __init__(self, capacity=None):\n",
    "        self.capacity = capacity\n",
    "        self.nodes = np.zeros((1,4), dtype=np.float32)\n",
    "    def addNode(self, label, demand, posX, posY):\n",
    "        newrow = np.array([label, demand, posX, posY], dtype=np.float32)\n",
    "        self.nodes = np.vstack((self.nodes, newrow))\n",
    "\n",
    "# Read the problem data file\n",
    "def readInput():\n",
    "\t# Create VRP object:\n",
    "    vrpManager = vrp()\n",
    "\t## First reading the VRP from the input ##\n",
    "    print('Reading data file...', end=' ')\n",
    "    fo = open('/home/conda_user/GA_VRP/test_set/P/P-n16-k8.vrp',\"r\")\n",
    "    lines = fo.readlines()\n",
    "    for i, line in enumerate(lines):\n",
    "        while line.upper().startswith('CAPACITY'):\n",
    "            inputs = line.split()\n",
    "            vrpManager.capacity = np.float32(inputs[2])\n",
    "\t\t\t# Validating positive non-zero capacity\n",
    "            if vrpManager.capacity <= 0:\n",
    "                print(sys.stderr, 'Invalid input: capacity must be neither negative nor zero!')\n",
    "                exit(1)\n",
    "            break       \n",
    "        while line.upper().startswith('NODE_COORD_SECTION'):\n",
    "            i += 1\n",
    "            line = lines[i]\n",
    "            while not (line.upper().startswith('DEMAND_SECTION') or line=='\\n'):\n",
    "                inputs = line.split()\n",
    "                vrpManager.addNode(np.int16(inputs[0]), 0.0, np.float32(inputs[1]), np.float32((inputs[2])))\n",
    "                # print(vrpManager.nodes)\n",
    "                i += 1\n",
    "                line = lines[i]\n",
    "                while (line=='\\n'):\n",
    "                    i += 1\n",
    "                    line = lines[i]\n",
    "                    if line.upper().startswith('DEMAND_SECTION'): break \n",
    "                if line.upper().startswith('DEMAND_SECTION'):\n",
    "                    i += 1\n",
    "                    line = lines[i] \n",
    "                    while not (line.upper().startswith('DEPOT_SECTION')):                  \n",
    "                        inputs = line.split()\n",
    "\t\t\t\t\t\t# Validating demand not greater than capacity\n",
    "                        if float(inputs[1]) > vrpManager.capacity:\n",
    "                            print(sys.stderr,\n",
    "\t\t\t\t\t\t\t'Invalid input: the demand of the node %s is greater than the vehicle capacity!' % vrpManager.nodes[0])\n",
    "                            exit(1)\n",
    "                        if float(inputs[1]) < 0:\n",
    "                            print(sys.stderr,\n",
    "                            'Invalid input: the demand of the node %s cannot be negative!' % vrpManager.nodes[0])\n",
    "                            exit(1)                            \n",
    "                        vrpManager.nodes[int(inputs[0])][1] =  float(inputs[1])\n",
    "                        i += 1\n",
    "                        line = lines[i]\n",
    "                        while (line=='\\n'):\n",
    "                            i += 1\n",
    "                            line = lines[i]\n",
    "                            if line.upper().startswith('DEPOT_SECTION'): break\n",
    "                        if line.upper().startswith('DEPOT_SECTION'):\n",
    "                            vrpManager.nodes = np.delete(vrpManager.nodes, 0, 0)                          \n",
    "                            print('Done.')\n",
    "                            return(vrpManager.capacity, vrpManager.nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Calculate fitness:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# define fitness kernel here:\n",
    "# @jit(nopython=True)\n",
    "def fitness(cost_table, individual):\n",
    "    zero_arr = np.zeros(1, dtype=np.int32)\n",
    "    zeroed_indiv = np.copy(individual)\n",
    "    \n",
    "    # nodes represent the row/column index in the cost table\n",
    "    for i in range(len(zeroed_indiv)):\n",
    "        zeroed_indiv[i] = zeroed_indiv[i] - 1\n",
    "        \n",
    "    if zeroed_indiv[0] != 0:\n",
    "        zeroed_indiv = np.hstack((zero_arr, zeroed_indiv))\n",
    "    if individual[-1] != 1:\n",
    "        zeroed_indiv = np.hstack((zeroed_indiv, zero_arr))\n",
    "        \n",
    "    fitness_val = 0\n",
    "    for i in range(len(zeroed_indiv)-1):\n",
    "        fitness_val += cost_table[int(zeroed_indiv[i]), int(zeroed_indiv[i+1])]\n",
    "        \n",
    "    return(fitness_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# define fitness kernel here:\n",
    "@cuda.jit\n",
    "def fitness_gpu(cost_table_d, individual_d, zeroed_indiv_d, fitness_val_d):     \n",
    "    \n",
    "    # nodes represent the row/column index in the cost table\n",
    "    threadId_row, threadId_col = cuda.grid(2)\n",
    "    \n",
    "    # Mapping between the 2D-grid indexing and the 1D-vector indexing:\n",
    "    index = threadId_row*(cuda.blockDim.x)+threadId_col\n",
    "    \n",
    "    fitness_val_d[0] = 0\n",
    "    if index+1 <= len(individual_d):\n",
    "        zeroed_indiv_d[index] = individual_d[index] - 1\n",
    "    \n",
    "    if index == 0 and zeroed_indiv_d[index] != 0:\n",
    "        cuda.atomic.add(fitness_val_d,0,cost_table_d[0, zeroed_indiv_d[index]])\n",
    "        cuda.atomic.add(fitness_val_d,0,cost_table_d[zeroed_indiv_d[index], zeroed_indiv_d[index+1]])\n",
    "    elif index == len(zeroed_indiv_d)-1 and zeroed_indiv_d[index] != 0:\n",
    "        cuda.atomic.add(fitness_val_d,0,cost_table_d[zeroed_indiv_d[index], 0])\n",
    "    elif index == len(zeroed_indiv_d)-1 and zeroed_indiv_d[index] == 0:\n",
    "        pass\n",
    "    elif index+1 <= len(zeroed_indiv_d):\n",
    "        cuda.atomic.add(fitness_val_d,0,cost_table_d[zeroed_indiv_d[index], zeroed_indiv_d[index+1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'blocks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-80cff3e985b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mfitness_val_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mfitness_gpu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mthreads_per_block\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost_table_d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindividual_d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzeroed_indiv_d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfitness_val_d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfitness_val_d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_to_host\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'blocks' is not defined"
     ]
    }
   ],
   "source": [
    "# Every individual MUST be initialized with length 2 * no._of_nodes\n",
    "\n",
    "individual = np.array([8,15,1,5,12,1,14,9,1,11,16,16,1,6,6,4,1,2,1,3,1,7,1,\\\n",
    "                      8,15,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0], dtype=np.int32)\n",
    "# individual = np.array(range(10000), dtype=np.int32)\n",
    "individual_d = cuda.to_device(individual)\n",
    "zeroed_indiv_d = cuda.to_device(individual)\n",
    "\n",
    "fitness_val_d = cuda.to_device(np.array([0], dtype=np.int32))\n",
    "\n",
    "fitness_gpu[blocks,threads_per_block](cost_table_d, individual_d, zeroed_indiv_d, fitness_val_d)\n",
    "print(fitness_val_d.copy_to_host()[0])\n",
    "\n",
    "###############################################################################################\n",
    "# Speed test of CPU and GPU versions of the function:\n",
    "# print(\"CPU time:\")\n",
    "# cost_table = np.zeros((data.shape[0], data.shape[0]), dtype=np.int32)\n",
    "# cost_table = calc_cost(data, popsize, vrp_capacity, cost_table)\n",
    "# %timeit fitness(cost_table, individual)\n",
    "# print(\"GPU time:\")\n",
    "# %timeit fitness_gpu[blocks,threads_per_block](cost_table_d, individual_d, zeroed_indiv_d, fitness_val_d)\n",
    "###############################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate cost table:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### CPU version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Calculate cost table:\n",
    "# @jit(nopython=True)\n",
    "def calc_cost(data, popsize, vrp_capacity, cost_table):\n",
    "    shifted_data = np.copy(data)\n",
    "    for i in range(len(shifted_data[:,0])):\n",
    "        shifted_data[i,0] = shifted_data[i,0] - 1\n",
    "\n",
    "    for row in range(len(shifted_data[:,0])):\n",
    "        for col in range(len(shifted_data[:,0])):\n",
    "            cost_table[row, col] = round(hypot((shifted_data[row,2] - shifted_data[col,2]),\\\n",
    "                                                       (shifted_data[row,3] - shifted_data[col,3])))\n",
    "    return cost_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate cost table:\n",
    "@cuda.jit\n",
    "def calc_cost_gpu(data_d, popsize, vrp_capacity, cost_table_d):\n",
    "    threadId_row, threadId_col = cuda.grid(2)\n",
    "    \n",
    "#     data_d[threadId_row,0] = data_d[threadId_row,0] - 1\n",
    "    \n",
    "####ceil() is used instead of round() as the latter crashes the kernel.\n",
    "####This causes +1 values in some cost distances\n",
    "\n",
    "    if (threadId_row <= data_d.shape[0]-1) and (threadId_col <= data_d.shape[0]-1):\n",
    "        cost_table_d[threadId_row, threadId_col] = ceil(hypot(data_d[threadId_row,2] - data_d[threadId_col,2],\\\n",
    "                                                              data_d[threadId_row,3] - data_d[threadId_col,3]))\n",
    "#     popArr = initializePop(data, popsize, vrp_capacity, cost_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize population:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### CPU version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Generating random initial population\n",
    "# @jit(nopython=True)\n",
    "def initializePop(data, popsize, vrp_capacity, cost_table):\n",
    "    popArr = [np.empty(1, np.int32)]\n",
    "    popArr.clear()\n",
    "    for i in range(popsize):\n",
    "        individual = np.asarray(data[:,0], dtype=np.int32)\n",
    "        random.shuffle(individual)\n",
    "#         individual = adjust(individual, data, vrp_capacity, cost_table)\n",
    "#         individual = np.hstack((np.asarray([0], dtype=np.int32), individual))\n",
    "#         popArr.append(individual)\n",
    "    return popArr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating random initial population\n",
    "@cuda.jit\n",
    "def initializePop_gpu(rng_states, data_d, pop_d):\n",
    "    threadId_row, threadId_col = cuda.grid(2)\n",
    "    \n",
    "    # Generate the individuals from the nodes in data_d:\n",
    "    if threadId_col <= data_d.shape[0]-1:\n",
    "        pop_d[threadId_row, threadId_col] = data_d[threadId_col, 0]\n",
    "    \n",
    "    # Randonly shuffle each individual on a separate thread:   \n",
    "    col = 0\n",
    "    if threadId_row <= pop_d.shape[0]-1 and threadId_col <= data_d.shape[0]-1 and threadId_col != 0:\n",
    "        while col == 0:\n",
    "            rnd = (xoroshiro128p_uniform_float32(rng_states, threadId_row*threadId_col)*(data_d.shape[0]-1))\n",
    "            col = int(rnd)+1\n",
    "\n",
    "        pop_d[threadId_row, threadId_col], pop_d[threadId_row, col] =\\\n",
    "        pop_d[threadId_row, col], pop_d[threadId_row, threadId_col]\n",
    "        \n",
    "    # Adjust individuals using adjust_gpu function:\n",
    "    # Calculate fitness of each individual using fitness_gpu function:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjust individuals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @jit(nopython=True)\n",
    "def adjust(individual, data, vrp_capacity, cost_table):\n",
    "\n",
    "    # Delete duplicate nodes\n",
    "    adjusted_indiv = np.zeros(individual.shape[0], dtype=np.int32)\n",
    "    j = 0\n",
    "    for i in range(len(individual)):\n",
    "        if not np.any(individual[i] == adjusted_indiv):\n",
    "            adjusted_indiv[j] = individual[i]\n",
    "            j += 1\n",
    "\n",
    "    # Delete ones and zeros\n",
    "    adjusted_indiv = np.delete(adjusted_indiv, np.where(adjusted_indiv==1)[0])\n",
    "    adjusted_indiv = np.delete(adjusted_indiv, np.where(adjusted_indiv==0)[0])\n",
    "\n",
    "    \n",
    "    # Insert missing nodes\n",
    "    for i in range(data.shape[0]):\n",
    "        if not np.any(data[i,0] == adjusted_indiv):\n",
    "            adjusted_indiv = np.hstack((adjusted_indiv, np.array([data[i,0]], dtype=np.int32)))\n",
    "\n",
    "    i = 0               # index\n",
    "    reqcap = 0.0        # required capacity\n",
    "\n",
    "    while i < len(adjusted_indiv): \n",
    "        if adjusted_indiv[i] != 1:\n",
    "            reqcap += data[data[:,0] == adjusted_indiv[i]][0,1]\n",
    "        else:\n",
    "            reqcap = 0\n",
    "        \n",
    "        if reqcap > vrp_capacity: \n",
    "            adjusted_indiv = np.hstack((adjusted_indiv[:i], np.array([1], dtype=np.int32), adjusted_indiv[i:]))\n",
    "            reqcap = 0.0\n",
    "        i += 1\n",
    "        \n",
    "    if adjusted_indiv[0] != 1:\n",
    "        adjusted_indiv = np.hstack((np.array([1], dtype=np.int32), adjusted_indiv))\n",
    "    if adjusted_indiv[-1] != 1:\n",
    "        adjusted_indiv = np.hstack((adjusted_indiv, np.array([1], dtype=np.int32)))\n",
    "    \n",
    "#     adjusted_indiv = np.hstack((adjusted_indiv, np.asarray([fitness(cost_table, adjusted_indiv)], dtype=np.int32)))\n",
    "    return adjusted_indiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def adjust_gpu(data_d, vrp_capacity, cost_table_d, missing_d, pop_d):\n",
    "    \n",
    "    # nodes represent the row/column index in the cost table\n",
    "    threadId_row, threadId_col = cuda.grid(2)\n",
    "    \n",
    "    # Remove duplicated elements from every single individual/row in population array:\n",
    "    r_flag = 9999 # A flag for removal/replacement\n",
    "    \n",
    "    if threadId_row <= pop_d.shape[0]-1 and threadId_col <= pop_d.shape[1]-1 and threadId_col != 0:\n",
    "                    \n",
    "        for i in range(threadId_col-1, -1, -1):\n",
    "            if pop_d[threadId_row, threadId_col] == pop_d[threadId_row, i]\\\n",
    "            and pop_d[threadId_row, threadId_col] != 0:\n",
    "                pop_d[threadId_row, threadId_col] = r_flag \n",
    "            \n",
    "        for j in range(data_d.shape[0]):\n",
    "            for i in range(threadId_col-1, -1, -1):\n",
    "                if data_d[j,0] == pop_d[threadId_row, i]:\n",
    "                    missing_d[threadId_row, j] = 0\n",
    "                    break\n",
    "                else:\n",
    "                    missing_d[threadId_row, j] = data_d[j,0]\n",
    "                     \n",
    "    # Add missing nodes to every single individual:\n",
    "            \n",
    "    if threadId_col == pop_d.shape[1]-1:\n",
    "        missing_elements = True\n",
    "        for i in range(missing_d.shape[1]):\n",
    "                if missing_d[threadId_row, i] != 0:\n",
    "                    missing_elements = True\n",
    "                    for j in range(pop_d.shape[1]):\n",
    "                        if pop_d[threadId_row, j] == r_flag:\n",
    "                            pop_d[threadId_row, j] = missing_d[threadId_row, i]\n",
    "                            missing_d[threadId_row, i] = 0\n",
    "                            break\n",
    "                else:\n",
    "                    missing_elements = False\n",
    "\n",
    "        if not missing_elements:\n",
    "        # shift individual's elements to the left for every inserted '1':\n",
    "            for i in range(pop_d.shape[1], 0, -1):\n",
    "                if pop_d[threadId_row, i] == r_flag:\n",
    "                    for j in range(i, pop_d.shape[1]-1):\n",
    "                        new_val = pop_d[threadId_row, j+1]\n",
    "                        pop_d[threadId_row, j] = new_val\n",
    "\n",
    "        reqcap = 0.0        # required capacity\n",
    "        for i in range(pop_d.shape[1]-1):\n",
    "            if pop_d[threadId_row, i] != 1 and pop_d[threadId_row, i] != 0:\n",
    "                reqcap += data_d[pop_d[threadId_row, i]-1, 1]\n",
    "                if reqcap > vrp_capacity:\n",
    "#                     # here will be the insert '1' algorithm:\n",
    "                    new_val = 1\n",
    "                    rep_val = pop_d[threadId_row, i]\n",
    "                    \n",
    "#                     # shift individual's elements to the right for every inserted '1': \n",
    "                    for j in range(i, pop_d.shape[1]-1):\n",
    "                        pop_d[threadId_row, j] = new_val\n",
    "                        new_val = rep_val\n",
    "                        rep_val = pop_d[threadId_row, j+1]\n",
    "                    reqcap = 0.0                    \n",
    "            else:\n",
    "                reqcap = 0.0\n",
    "                \n",
    "            \n",
    "            # The last part is to add the individual's fitness value at the very end of it.\n",
    "#             pop_d[threadId_row, -1] = # individual's fitness value\n",
    "\n",
    "#     while i < len(adjusted_indiv): \n",
    "#         if adjusted_indiv[i] != 1:\n",
    "#             reqcap += data[data[:,0] == adjusted_indiv[i]][0,1]\n",
    "#         else:\n",
    "#             reqcap = 0\n",
    "        \n",
    "#         if reqcap > vrp_capacity: \n",
    "#             adjusted_indiv = np.hstack((adjusted_indiv[:i], np.array([1], dtype=np.int32), adjusted_indiv[i:]))\n",
    "#             reqcap = 0.0\n",
    "#         i += 1\n",
    "        \n",
    "#     if adjusted_indiv[0] != 1:\n",
    "#         adjusted_indiv = np.hstack((np.array([1], dtype=np.int32), adjusted_indiv))\n",
    "#     if adjusted_indiv[-1] != 1:\n",
    "#         adjusted_indiv = np.hstack((adjusted_indiv, np.array([1], dtype=np.int32)))\n",
    "    \n",
    "# #     adjusted_indiv = np.hstack((adjusted_indiv, np.asarray([fitness(cost_table, adjusted_indiv)], dtype=np.int32)))\n",
    "#     return adjusted_indiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  0 11 12  5 13  0  2  0 15 14  7  0  0  9 16  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0]\n",
      "-----------------------\n"
     ]
    },
    {
     "ename": "CudaAPIError",
     "evalue": "[700] Call to cuMemcpyDtoH results in UNKNOWN_CUDA_ERROR",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCudaAPIError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-6b5e1ff8673e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0madjust_gpu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mthreads_per_block\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvrp_capacity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost_table_d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing_d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpop_d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# print(missing_d.copy_to_host()[50:65,:])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpop_d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_to_host\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# fitness_gpu[blocks,threads_per_block](cost_table_d, adjusted_indiv, zeroed_indiv_d, fitness_val_d)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pycuda_env/lib/python3.7/site-packages/numba/cuda/cudadrv/devices.py\u001b[0m in \u001b[0;36m_require_cuda_context\u001b[0;34m(*args, **kws)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_require_cuda_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkws\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0mget_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkws\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_require_cuda_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pycuda_env/lib/python3.7/site-packages/numba/cuda/cudadrv/devicearray.py\u001b[0m in \u001b[0;36mcopy_to_host\u001b[0;34m(self, ary, stream)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malloc_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m             \u001b[0m_driver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_to_host\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhostary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malloc_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mary\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pycuda_env/lib/python3.7/site-packages/numba/cuda/cudadrv/driver.py\u001b[0m in \u001b[0;36mdevice_to_host\u001b[0;34m(dst, src, size, stream)\u001b[0m\n\u001b[1;32m   1854\u001b[0m         \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuMemcpyDtoH\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1856\u001b[0;31m     \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost_pointer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_pointer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mvarargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1858\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pycuda_env/lib/python3.7/site-packages/numba/cuda/cudadrv/driver.py\u001b[0m in \u001b[0;36msafe_cuda_api_call\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0m_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'call driver api: %s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0mretcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msafe_cuda_api_call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pycuda_env/lib/python3.7/site-packages/numba/cuda/cudadrv/driver.py\u001b[0m in \u001b[0;36m_check_error\u001b[0;34m(self, fname, retcode)\u001b[0m\n\u001b[1;32m    326\u001b[0m                     \u001b[0m_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_getpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mCudaDriverError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CUDA initialized before forking\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mCudaAPIError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevnum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCudaAPIError\u001b[0m: [700] Call to cuMemcpyDtoH results in UNKNOWN_CUDA_ERROR"
     ]
    }
   ],
   "source": [
    "# zeros = np.zeros(individual_d.shape[0], dtype=np.int32)\n",
    "# adjusted_indiv = cuda.to_device(zeros)\n",
    "zeros = np.zeros(shape=(popsize, pop_d.shape[1]), dtype=np.int32)\n",
    "missing_d = cuda.to_device(zeros)\n",
    "\n",
    "print(pop_d.copy_to_host()[80,:], end='\\n-----------------------\\n')\n",
    "#%timeit adjust_gpu[blocks,threads_per_block]\\\n",
    " #(data_d, vrp_capacity, cost_table_d, missing_d, pop_d)\n",
    "adjust_gpu[blocks,threads_per_block](data_d, vrp_capacity, cost_table_d, missing_d, pop_d)\n",
    "# print(missing_d.copy_to_host()[50:65,:])\n",
    "print(pop_d.copy_to_host()[80,:])\n",
    "\n",
    "# fitness_gpu[blocks,threads_per_block](cost_table_d, adjusted_indiv, zeroed_indiv_d, fitness_val_d)\n",
    "# print(fitness_val_d.copy_to_host()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data file... Done.\n"
     ]
    },
    {
     "ename": "CudaAPIError",
     "evalue": "[700] Call to cuMemAlloc results in UNKNOWN_CUDA_ERROR",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCudaAPIError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-4d0cee08fb47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mgenerations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m7000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdata_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mcost_table_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pycuda_env/lib/python3.7/site-packages/numba/cuda/cudadrv/devices.py\u001b[0m in \u001b[0;36m_require_cuda_context\u001b[0;34m(*args, **kws)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_require_cuda_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkws\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0mget_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkws\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_require_cuda_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pycuda_env/lib/python3.7/site-packages/numba/cuda/api.py\u001b[0m in \u001b[0;36mto_device\u001b[0;34m(obj, stream, copy, to)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \"\"\"\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mto\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0mto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevicearray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pycuda_env/lib/python3.7/site-packages/numba/cuda/cudadrv/devicearray.py\u001b[0m in \u001b[0;36mauto_device\u001b[0;34m(obj, stream, copy)\u001b[0m\n\u001b[1;32m    691\u001b[0m                 subok=True)\n\u001b[1;32m    692\u001b[0m             \u001b[0msentry_contiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0mdevobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrom_array_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0mdevobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pycuda_env/lib/python3.7/site-packages/numba/cuda/cudadrv/devicearray.py\u001b[0m in \u001b[0;36mfrom_array_like\u001b[0;34m(ary, stream, gpu_data)\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0mary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m     return DeviceNDArray(ary.shape, ary.strides, ary.dtype,\n\u001b[0;32m--> 631\u001b[0;31m                          writeback=ary, stream=stream, gpu_data=gpu_data)\n\u001b[0m\u001b[1;32m    632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pycuda_env/lib/python3.7/site-packages/numba/cuda/cudadrv/devicearray.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, shape, strides, dtype, stream, writeback, gpu_data)\u001b[0m\n\u001b[1;32m    100\u001b[0m                                                                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                                                                 self.dtype.itemsize)\n\u001b[0;32m--> 102\u001b[0;31m                 \u001b[0mgpu_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemalloc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malloc_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malloc_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_driver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_memory_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pycuda_env/lib/python3.7/site-packages/numba/cuda/cudadrv/driver.py\u001b[0m in \u001b[0;36mmemalloc\u001b[0;34m(self, bytesize)\u001b[0m\n\u001b[1;32m    698\u001b[0m             \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuMemAlloc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytesize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 700\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_attempt_allocation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mallocator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0mfinalizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_alloc_finalizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytesize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pycuda_env/lib/python3.7/site-packages/numba/cuda/cudadrv/driver.py\u001b[0m in \u001b[0;36m_attempt_allocation\u001b[0;34m(self, allocator)\u001b[0m\n\u001b[1;32m    681\u001b[0m         \"\"\"\n\u001b[1;32m    682\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 683\u001b[0;31m             \u001b[0mallocator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    684\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCudaAPIError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m             \u001b[0;31m# is out-of-memory?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pycuda_env/lib/python3.7/site-packages/numba/cuda/cudadrv/driver.py\u001b[0m in \u001b[0;36mallocator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mallocator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 698\u001b[0;31m             \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuMemAlloc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytesize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_attempt_allocation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mallocator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pycuda_env/lib/python3.7/site-packages/numba/cuda/cudadrv/driver.py\u001b[0m in \u001b[0;36msafe_cuda_api_call\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0m_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'call driver api: %s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0mretcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msafe_cuda_api_call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pycuda_env/lib/python3.7/site-packages/numba/cuda/cudadrv/driver.py\u001b[0m in \u001b[0;36m_check_error\u001b[0;34m(self, fname, retcode)\u001b[0m\n\u001b[1;32m    326\u001b[0m                     \u001b[0m_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_getpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mCudaDriverError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CUDA initialized before forking\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mCudaAPIError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevnum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCudaAPIError\u001b[0m: [700] Call to cuMemAlloc results in UNKNOWN_CUDA_ERROR"
     ]
    }
   ],
   "source": [
    "vrp_capacity, data = readInput()\n",
    "popsize = 100\n",
    "generations = 7000\n",
    "\n",
    "data_d = cuda.to_device(data)\n",
    "cost_table_d = cuda.device_array(shape=(data.shape[0], data.shape[0]), dtype=np.int32)\n",
    "\n",
    "pop = np.zeros((popsize, 2*data.shape[0]+2), dtype=np.int32)\n",
    "pop_d = cuda.to_device(pop)\n",
    "\n",
    "# GPU grid configurations:\n",
    "threads_per_block = (10, 10)\n",
    "blocks_no = (2*data.shape[0])*popsize/pow(threads_per_block[0],2)\n",
    "blocks = (ceil(blocks_no), ceil(blocks_no))\n",
    "rng_states = create_xoroshiro128p_states(threads_per_block[0]**2  * blocks[0]**2, seed=1)\n",
    "calc_cost_gpu[blocks, threads_per_block](data_d, popsize, vrp_capacity, cost_table_d)\n",
    "\n",
    "initializePop_gpu[blocks, threads_per_block](rng_states, data_d, pop_d)\n",
    "\n",
    "# print(pop_d.copy_to_host()[30:50,:])\n",
    "# print(cost_table_d.copy_to_host())\n",
    "###############################################################################################\n",
    "# Speed test of CPU and GPU versions of the function:\n",
    "# cost_table = np.zeros((data.shape[0],data.shape[0]), dtype=np.int32)\n",
    "# print(calc_cost(data, popsize, vrp_capacity, cost_table).shape)\n",
    "# print('CPU time:')\n",
    "# %timeit calc_cost(data, popsize, vrp_capacity, cost_table)\n",
    "# print('GPU time:')\n",
    "#%timeit calc_cost_gpu[blocks, threads_per_block](data_d, popsize, vrp_capacity, cost_table_d)\n",
    "################################################################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
